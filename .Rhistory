elapsed_time = difftime(end_time, start_time, units = c("hours")),
daily_mean_pm = mean(pm),
daily_95_pm = quantile(pm, .95),
daily_mean_rh = mean(rh),
daily_mean_t = mean(t))
recent_daily <- recent_daily %>%
mutate(
day = as.Date(start_time),
across(c('elapsed_time', 'daily_mean_pm', 'daily_95_pm', 'daily_mean_rh', 'daily_mean_t'), round, 1)) %>%
select(location, device, filter, day, elapsed_time, n_readings, daily_mean_pm, daily_95_pm, daily_mean_rh, daily_mean_t)%>%
arrange(day)
#24-hour groups for ALL data -----------------------------
all_df <- all_df %>%
group_by(location, device, filter) %>% # group by location, device ID, filter ID
mutate(
start_time = min(time), #start time for cartridge ID
latest_time = max(time), #end time for cartridge ID
total_run_time = as.numeric(difftime(latest_time, start_time, units = "hours")), #total run time for cartridge ID
elapsed_time = as.numeric(difftime(time, start_time, units = "hours")) #elapsed time of current row for cartridge ID
) %>%
mutate(interval = (elapsed_time %/% 24) + 1) %>% #create index for number of 24-hours periods (1-based)
ungroup()
all_daily <- all_df %>% #create stats by interval
group_by(location, device, filter, interval) %>% #for each unique 24-hour interval by device...
reframe(    start_time = min(time),
end_time = max(time),
n_readings = n(),
elapsed_time = difftime(end_time, start_time, units = c("hours")),
daily_mean_pm = mean(pm),
daily_95_pm = quantile(pm, .95),
daily_mean_rh = mean(rh),
daily_mean_t = mean(t))
all_daily <- all_daily %>%
mutate(
day = as.Date(start_time),
across(c('elapsed_time', 'daily_mean_pm', 'daily_95_pm', 'daily_mean_rh', 'daily_mean_t'), round, 1)) %>%
select(location, device, filter, day, elapsed_time, n_readings, daily_mean_pm, daily_95_pm, daily_mean_rh, daily_mean_t)%>%
arrange(day)
write.csv(recent_daily, "recent_daily.csv", row.names = FALSE) #for table
write.csv(all_daily, "all_daily.csv", row.names = FALSE)
rm(list = ls())
runApp()
library(tidyr)
runApp()
runApp()
runApp()
all_daily <- read_csv("all_daily.csv", show_col_types = FALSE)
View(all_daily)
runApp()
selected_data <- all_daily %>% filter(location == input$location)
selectInput("location", "Select A Location:", choices = locations, selected = "Amity University Noida, India")
# Global variables for app
locations <- c("Pretoria, South Africa", "Taichung, Taiwan", "Tainan, Taiwan", "Delhi, India",
"Amity University Noida, India", "Amity University Manesar, India", "Adama, Ethiopia",
"AASTU, Ethiopia")
all_recent_df <- read_csv("all_recent_data.csv", show_col_types = FALSE) #for plotting recent data
recent_daily <- read_csv("recent_daily.csv", show_col_types = FALSE) # for recent stats
all_daily <- read_csv("all_daily.csv", show_col_types = FALSE)
# Define UI
ui <- navbarPage(
title = 'AMOD/S Data Visualization App for MAIA + CEAMS',
tabPanel(
fluidPage(
fluidRow(
column(12,
selectInput("location", "Select A Location:", choices = locations, selected = "Amity University Noida, India")
selected_data <- all_daily %>% filter(location == input$location)
View(all_daily)
devices <- device_pairs[[input$location]]
device_pairs <- list(
"Tainan, Taiwan" = c("AD00092", "AD00101"),
"AASTU, Ethiopia" = c("AD00091", "AD00098"),
"Pretoria, South Africa" = c("AD00103", "AD00104"),
"Tainan, Taiwan" = c("AD00403", "AD00406"),
"Amity University Manesar, India" = c("AD00408", "AD00409"),
"Adama, Ethiopia" = c("AD00410", "AD00412"),
"Amity University Noida, India" = c("AD00413", "AD00414")
#Some India spot new = c("415", "416")
)
# Get the devices for the selected location
devices <- device_pairs[[input$location]]
runApp()
runApp()
runApp()
runApp()
selected_data <- all_daily %>% filter(location = "Amity Noida University, India")
selected_data <- all_daily %>% filter(location == "Amity Noida University, India")
devices = device_pairs[["Amity Noida University, India"]]
View(device_pairs)
View(device_pairs)
devices = device_pairs[["Amity Noida University, India"]]
devices = device_pairs[["Amity University Noida, India"]]
View(selected_data)
pm_data_device1 <- selected_data %>%
filter(device == devices[1]) %>%
select(day, pm_device1 = daily_mean_pm)
selected_data <- all_daily %>% filter(location == "Amity University Noida, India)
> selected_data <- all_daily %>% filter(location == "Amity University Noida, India")
selected_data <- all_daily %>% filter(location == "Amity University Noida, India")
View(selected_data)
pm_data_device1 <- selected_data %>%
filter(device == devices[1]) %>%
select(day, pm_device1 = daily_mean_pm)
View(pm_data_device1)
pm_data_device2 <- selected_data %>%
filter(device == devices[2]) %>%
select(day, pm_device2 = daily_mean_pm)
View(pm_data_device2)
merged_pm_data <- inner_join(pm_data_device1, pm_data_device2, by = "day")
View(merged_pm_data)
runApp()
ggplot(merged_pm_data, aes(x = pm_data_device1, y = pm_data_device2)) +
geom_point() +
geom_abline(slope = 1, intercept = 0, color = "grey", linetype = "dashed") +
labs(title = paste("Daily PM2.5 Comparison: Device", devices[1], "vs", devices[2]),
x = paste("PM2.5 (Device", devices[1], ")"),
y = paste("PM2.5 (Device", devices[2], ")")) +
theme_minimal()
View(pm_data_device1)
View(merged_pm_data)
ggplot(merged_pm_data, aes(x = pm_device1, y = pm_device2)) +
geom_point() +
#geom_abline(slope = 1, intercept = 0, color = "grey", linetype = "dashed") +
labs(title = paste("Daily PM2.5 Comparison: Device", devices[1], "vs", devices[2]),
x = paste("PM2.5 (Device", devices[1], ")"),
y = paste("PM2.5 (Device", devices[2], ")")) +
theme_minimal()
runApp()
ggplot(merged_pm_data, aes(x = pm_device1, y = pm_device2)) +
geom_point() +
geom_abline(slope = 1, intercept = 0, color = "grey", linetype = "dashed") +
labs(title = paste("Daily Averaged PM2.5 Comparison: Device", devices[1], "vs", devices[2]),
x = paste("Device", devices[1]),
y = paste("Device", devices[2])) +
theme_minimal()
runApp()
all_data <- rename(all_data,
lat = latitude,
lng = longitude,
device = sn,
time = timestamp_utc,
filter = cartridge_id,
flow = volumetric_flowrate,
pressure = fdpdp,
rh = pump_rh,
t = pump_t,
pm = pm25)
all_data <- read.csv("all_data.csv")
# Keep only the specified columns
all_data <- all_data %>%
select(cartridge_id, latitude, longitude, sn, timestamp_utc, pm25, fdpdp, volumetric_flowrate, pump_rh, pump_t)
all_data <- read.csv("all_data.csv") #comment
all_data <- rename(all_data,
lat = latitude,
lng = longitude,
device = sn,
time = timestamp_utc,
filter = cartridge_id,
flow = volumetric_flowrate,
pressure = fdpdp,
rh = pump_rh,
t = pump_t,
pm = pm25)
View(all_data)
#Run this if not pulling from get_ceams_data
all_data <- read.csv("all_data.csv") #comment
#summary statistics:
#24-hour groups for recent data -----------------------------
all_recent_df <- all_recent_df %>%
group_by(location, device, filter) %>% # group by location, device ID, filter ID
mutate(
start_time = min(time), #start time for cartridge ID
latest_time = max(time), #end time for cartridge ID
total_run_time = as.numeric(difftime(latest_time, start_time, units = "hours")), #total run time for cartridge ID
elapsed_time = as.numeric(difftime(time, start_time, units = "hours")) #elapsed time of current row for cartridge ID
) %>%
mutate(interval = (elapsed_time %/% 24) + 1) %>% #create index for number of 24-hours periods (1-based)
ungroup()
recent_daily <- all_recent_df %>% #create stats by interval
group_by(location, device, filter, interval) %>% #for each unique 24-hour interval by device...
reframe(    start_time = min(time),
end_time = max(time),
n_readings = n(),
elapsed_time = difftime(end_time, start_time, units = c("hours")),
daily_mean_pm = mean(pm),
daily_95_pm = quantile(pm, .95),
daily_mean_rh = mean(rh),
daily_mean_t = mean(t))
recent_daily <- recent_daily %>%
mutate(
day = as.Date(start_time),
across(c('elapsed_time', 'daily_mean_pm', 'daily_95_pm', 'daily_mean_rh', 'daily_mean_t'), round, 1)) %>%
select(location, device, filter, day, elapsed_time, n_readings, daily_mean_pm, daily_95_pm, daily_mean_rh, daily_mean_t)%>%
desc(day)
#Run this if not pulling from get_ceams_data
all_data <- read.csv("all_data.csv") #comment
#summary statistics:
#24-hour groups for recent data -----------------------------
all_recent_df <- all_recent_df %>%
group_by(location, device, filter) %>% # group by location, device ID, filter ID
mutate(
start_time = min(time), #start time for cartridge ID
latest_time = max(time), #end time for cartridge ID
total_run_time = as.numeric(difftime(latest_time, start_time, units = "hours")), #total run time for cartridge ID
elapsed_time = as.numeric(difftime(time, start_time, units = "hours")) #elapsed time of current row for cartridge ID
) %>%
mutate(interval = (elapsed_time %/% 24) + 1) %>% #create index for number of 24-hours periods (1-based)
ungroup()
recent_daily <- all_recent_df %>% #create stats by interval
group_by(location, device, filter, interval) %>% #for each unique 24-hour interval by device...
reframe(    start_time = min(time),
end_time = max(time),
n_readings = n(),
elapsed_time = difftime(end_time, start_time, units = c("hours")),
daily_mean_pm = mean(pm),
daily_95_pm = quantile(pm, .95),
daily_mean_rh = mean(rh),
daily_mean_t = mean(t))
recent_daily <- recent_daily %>%
mutate(
day = as.Date(start_time),
across(c('elapsed_time', 'daily_mean_pm', 'daily_95_pm', 'daily_mean_rh', 'daily_mean_t'), round, 1)) %>%
select(location, device, filter, day, elapsed_time, n_readings, daily_mean_pm, daily_95_pm, daily_mean_rh, daily_mean_t)%>%
arrange(desc(day))
#24-hour groups for ALL data -----------------------------
all_df <- all_df %>%
group_by(location, device, filter) %>% # group by location, device ID, filter ID
mutate(
start_time = min(time), #start time for cartridge ID
latest_time = max(time), #end time for cartridge ID
total_run_time = as.numeric(difftime(latest_time, start_time, units = "hours")), #total run time for cartridge ID
elapsed_time = as.numeric(difftime(time, start_time, units = "hours")) #elapsed time of current row for cartridge ID
) %>%
mutate(interval = (elapsed_time %/% 24) + 1) %>% #create index for number of 24-hours periods (1-based)
ungroup()
#Group location by device ID ------------------
pretoria <- all_data %>%
filter(device == 'AD00103' | device == 'AD00104' | device == 'AD00405' )%>%
mutate(location = 'Pretoria, South Africa')
pretoria_recent <- pretoria %>%
filter(time >= Sys.Date() - 14)%>%
mutate(location = 'Pretoria, South Africa')
taichung <- all_data %>%
filter(device == 'AD00094')%>%
mutate(location = 'Taichung, Taiwan')
taichung_recent <- taichung %>%
filter(time >= Sys.Date() - 14)%>%
mutate(location = 'Taichung, Taiwan')
tainan <- all_data %>%
filter(device == 'AD00092' | device == 'AD00101' | device == 'AD00403' | device == 'AD00406')%>%
mutate(location = 'Tainan, Taiwan')
tainan_recent <- tainan %>%
filter(time >= Sys.Date() - 14)%>%
mutate(location = 'Tainan, Taiwan')
delhi <- all_data %>%
filter(device == 'AD00096')%>%
mutate(location = 'Delhi, India')
delhi_recent <- delhi %>%
filter(time >= Sys.Date() - 14)%>%
mutate(location = 'Delhi, India')
noida <- all_data %>%
filter(device == 'AD00088' | device == 'AD00090' | device == 'AD00413' | device == 'AD00414')%>%
mutate(location = 'Amity University Noida, India')
noida_recent <- noida %>%
filter(time >= Sys.Date() - 14)%>%
mutate(location = 'Amity University Noida, India')
manesar <- all_data %>%
filter(device == 'AD00408' | device == 'AD00409')%>%
mutate(location = 'Amity University Manesar, India')
manesar_recent <- manesar %>%
filter(time >= Sys.Date() - 14)%>%
mutate(location = 'Amity University Manesar, India')
adama <- all_data %>%
filter(device == 'AD00410' | device == 'AD00412')%>%
mutate(location = 'Adama, Ethiopia')
adama_recent <- adama %>%
filter(time >= Sys.Date() - 14)%>%
mutate(location = 'Adama, Ethiopia')
aastu <- all_data %>%
filter(device == 'AD00091' | device == 'AD00098' | device == 'AD00093')%>%
mutate(location = 'AASTU, Ethiopia')
aastu_recent <- aastu %>%
filter(time >= Sys.Date() - 14)%>%
mutate(location = 'AASTU, Ethiopia')
all_recent_df <- rbind(pretoria_recent, taichung_recent, tainan_recent, delhi_recent, noida_recent, manesar_recent, adama_recent, aastu_recent)
all_df <- rbind(pretoria, taichung, tainan, delhi, noida, manesar, adama, aastu)
#write all data tables
write.csv(all_recent_df, "all_recent_data.csv", row.names = FALSE) #for plot
write.csv(all_df, "all_data.csv", row.names = FALSE) #all data
#Run this if not pulling from get_ceams_data
all_data <- read.csv("all_data.csv") #comment
#summary statistics:
#24-hour groups for recent data -----------------------------
all_recent_df <- all_recent_df %>%
group_by(location, device, filter) %>% # group by location, device ID, filter ID
mutate(
start_time = min(time), #start time for cartridge ID
latest_time = max(time), #end time for cartridge ID
total_run_time = as.numeric(difftime(latest_time, start_time, units = "hours")), #total run time for cartridge ID
elapsed_time = as.numeric(difftime(time, start_time, units = "hours")) #elapsed time of current row for cartridge ID
) %>%
mutate(interval = (elapsed_time %/% 24) + 1) %>% #create index for number of 24-hours periods (1-based)
ungroup()
recent_daily <- all_recent_df %>% #create stats by interval
group_by(location, device, filter, interval) %>% #for each unique 24-hour interval by device...
reframe(    start_time = min(time),
end_time = max(time),
n_readings = n(),
elapsed_time = difftime(end_time, start_time, units = c("hours")),
daily_mean_pm = mean(pm),
daily_95_pm = quantile(pm, .95),
daily_mean_rh = mean(rh),
daily_mean_t = mean(t))
recent_daily <- recent_daily %>%
mutate(
day = as.Date(start_time),
across(c('elapsed_time', 'daily_mean_pm', 'daily_95_pm', 'daily_mean_rh', 'daily_mean_t'), round, 1)) %>%
select(location, device, filter, day, elapsed_time, n_readings, daily_mean_pm, daily_95_pm, daily_mean_rh, daily_mean_t)%>%
arrange(desc(day))
#24-hour groups for ALL data -----------------------------
all_df <- all_df %>%
group_by(location, device, filter) %>% # group by location, device ID, filter ID
mutate(
start_time = min(time), #start time for cartridge ID
latest_time = max(time), #end time for cartridge ID
total_run_time = as.numeric(difftime(latest_time, start_time, units = "hours")), #total run time for cartridge ID
elapsed_time = as.numeric(difftime(time, start_time, units = "hours")) #elapsed time of current row for cartridge ID
) %>%
mutate(interval = (elapsed_time %/% 24) + 1) %>% #create index for number of 24-hours periods (1-based)
ungroup()
all_daily <- all_df %>% #create stats by interval
group_by(location, device, filter, interval) %>% #for each unique 24-hour interval by device...
reframe(    start_time = min(time),
end_time = max(time),
n_readings = n(),
elapsed_time = difftime(end_time, start_time, units = c("hours")),
daily_mean_pm = mean(pm),
daily_95_pm = quantile(pm, .95),
daily_mean_rh = mean(rh),
daily_mean_t = mean(t))
all_daily <- all_daily %>%
mutate(
day = as.Date(start_time),
across(c('elapsed_time', 'daily_mean_pm', 'daily_95_pm', 'daily_mean_rh', 'daily_mean_t'), round, 1)) %>%
select(location, device, filter, day, elapsed_time, n_readings, daily_mean_pm, daily_95_pm, daily_mean_rh, daily_mean_t)%>%
arrange(desc(day))
#write daily tables
write.csv(recent_daily, "recent_daily.csv", row.names = FALSE) #for table
write.csv(all_daily, "all_daily.csv", row.names = FALSE)
runApp()
traceback()
#process all data from get_ceams_data
#This script is scheduled to run every 3 days on my task scheduler
rm(list = ls())
library(dplyr)
library(lubridate)
source("get_ceams_data.R")
# List of device IDs
device_ids <- c(
# Pretoria, South Africa
'AD00103', 'AD00104', 'AD00405',
# Taichung, Taiwan
'AD00094',
# Tainan, Taiwan
'AD00092','AD00101','AD00403','AD00406',
# Delhi, India
'AD00096',
# Amity University Noida, India (88 starting in 2024)
'AD00088','AD00090','AD00413','AD00414',
# Amity University Manesar, India
'AD00408','AD00409',
# Adama, Ethiopia
'AD00410','AD00412',
#AASTU Addis Ababa, Ethiopia
'AD00091','AD00098','AD00093')
all_data <- get_ceams_data(device_ids) #call function in get_ceams_data.R
# Keep only the specified columns
all_data <- all_data %>%
select(cartridge_id, latitude, longitude, sn, timestamp_utc, pm25, fdpdp, volumetric_flowrate, pump_rh, pump_t)
all_data <- rename(all_data,
lat = latitude,
lng = longitude,
device = sn,
time = timestamp_utc,
filter = cartridge_id,
flow = volumetric_flowrate,
pressure = fdpdp,
rh = pump_rh,
t = pump_t,
pm = pm25)
all_data <- all_data %>%
filter(!is.na(time)) %>%
filter(pm > 0) %>%
filter(!is.na(pm)) %>%
filter(pm < quantile(pm, 0.9999))
all_data$time <- as.POSIXct(all_data$time, format= "%Y-%m-%dT%H:%M")
start_size = nrow(all_data) #size of all data pre-process
#Group location by device ID ------------------
pretoria <- all_data %>%
filter(device == 'AD00103' | device == 'AD00104' | device == 'AD00405' )%>%
mutate(location = 'Pretoria, South Africa')
pretoria_recent <- pretoria %>%
filter(time >= Sys.Date() - 14)%>%
mutate(location = 'Pretoria, South Africa')
taichung <- all_data %>%
filter(device == 'AD00094')%>%
mutate(location = 'Taichung, Taiwan')
taichung_recent <- taichung %>%
filter(time >= Sys.Date() - 14)%>%
mutate(location = 'Taichung, Taiwan')
tainan <- all_data %>%
filter(device == 'AD00092' | device == 'AD00101' | device == 'AD00403' | device == 'AD00406')%>%
mutate(location = 'Tainan, Taiwan')
tainan_recent <- tainan %>%
filter(time >= Sys.Date() - 14)%>%
mutate(location = 'Tainan, Taiwan')
delhi <- all_data %>%
filter(device == 'AD00096')%>%
mutate(location = 'Delhi, India')
delhi_recent <- delhi %>%
filter(time >= Sys.Date() - 14)%>%
mutate(location = 'Delhi, India')
noida <- all_data %>%
filter(device == 'AD00088' | device == 'AD00090' | device == 'AD00413' | device == 'AD00414')%>%
mutate(location = 'Amity University Noida, India')
noida_recent <- noida %>%
filter(time >= Sys.Date() - 14)%>%
mutate(location = 'Amity University Noida, India')
manesar <- all_data %>%
filter(device == 'AD00408' | device == 'AD00409')%>%
mutate(location = 'Amity University Manesar, India')
manesar_recent <- manesar %>%
filter(time >= Sys.Date() - 14)%>%
mutate(location = 'Amity University Manesar, India')
adama <- all_data %>%
filter(device == 'AD00410' | device == 'AD00412')%>%
mutate(location = 'Adama, Ethiopia')
adama_recent <- adama %>%
filter(time >= Sys.Date() - 14)%>%
mutate(location = 'Adama, Ethiopia')
aastu <- all_data %>%
filter(device == 'AD00091' | device == 'AD00098' | device == 'AD00093')%>%
mutate(location = 'AASTU, Ethiopia')
aastu_recent <- aastu %>%
filter(time >= Sys.Date() - 14)%>%
mutate(location = 'AASTU, Ethiopia')
all_recent_df <- rbind(pretoria_recent, taichung_recent, tainan_recent, delhi_recent, noida_recent, manesar_recent, adama_recent, aastu_recent)
all_df <- rbind(pretoria, taichung, tainan, delhi, noida, manesar, adama, aastu)
#write all data tables
write.csv(all_recent_df, "all_recent_data.csv", row.names = FALSE) #for plot
write.csv(all_df, "all_data.csv", row.names = FALSE) #all data
#Run this if not pulling from get_ceams_data
all_data <- read.csv("all_data.csv") #comment
#summary statistics:
#24-hour groups for recent data -----------------------------
all_recent_df <- all_recent_df %>%
group_by(location, device, filter) %>% # group by location, device ID, filter ID
mutate(
start_time = min(time), #start time for cartridge ID
latest_time = max(time), #end time for cartridge ID
total_run_time = as.numeric(difftime(latest_time, start_time, units = "hours")), #total run time for cartridge ID
elapsed_time = as.numeric(difftime(time, start_time, units = "hours")) #elapsed time of current row for cartridge ID
) %>%
mutate(interval = (elapsed_time %/% 24) + 1) %>% #create index for number of 24-hours periods (1-based)
ungroup()
recent_daily <- all_recent_df %>% #create stats by interval
group_by(location, device, filter, interval) %>% #for each unique 24-hour interval by device...
reframe(    start_time = min(time),
end_time = max(time),
n_readings = n(),
elapsed_time = difftime(end_time, start_time, units = c("hours")),
daily_mean_pm = mean(pm),
daily_95_pm = quantile(pm, .95),
daily_mean_rh = mean(rh),
daily_mean_t = mean(t))
recent_daily <- recent_daily %>%
mutate(
day = as.Date(start_time),
across(c('elapsed_time', 'daily_mean_pm', 'daily_95_pm', 'daily_mean_rh', 'daily_mean_t'), round, 1)) %>%
select(location, device, filter, day, elapsed_time, n_readings, daily_mean_pm, daily_95_pm, daily_mean_rh, daily_mean_t)%>%
arrange(desc(day))
#24-hour groups for ALL data -----------------------------
all_df <- all_df %>%
group_by(location, device, filter) %>% # group by location, device ID, filter ID
mutate(
start_time = min(time), #start time for cartridge ID
latest_time = max(time), #end time for cartridge ID
total_run_time = as.numeric(difftime(latest_time, start_time, units = "hours")), #total run time for cartridge ID
elapsed_time = as.numeric(difftime(time, start_time, units = "hours")) #elapsed time of current row for cartridge ID
) %>%
mutate(interval = (elapsed_time %/% 24) + 1) %>% #create index for number of 24-hours periods (1-based)
ungroup()
all_daily <- all_df %>% #create stats by interval
group_by(location, device, filter, interval) %>% #for each unique 24-hour interval by device...
reframe(    start_time = min(time),
end_time = max(time),
n_readings = n(),
elapsed_time = difftime(end_time, start_time, units = c("hours")),
daily_mean_pm = mean(pm),
daily_95_pm = quantile(pm, .95),
daily_mean_rh = mean(rh),
daily_mean_t = mean(t))
all_daily <- all_daily %>%
mutate(
day = as.Date(start_time),
across(c('elapsed_time', 'daily_mean_pm', 'daily_95_pm', 'daily_mean_rh', 'daily_mean_t'), round, 1)) %>%
select(location, device, filter, day, elapsed_time, n_readings, daily_mean_pm, daily_95_pm, daily_mean_rh, daily_mean_t)%>%
arrange(desc(day))
#write daily tables
write.csv(recent_daily, "recent_daily.csv", row.names = FALSE) #for table
write.csv(all_daily, "all_daily.csv", row.names = FALSE)
shiny::runApp()
